\chapter{Appendice: Progetti Completi}\label{app:esercizi}

\section{Introduzione}
Questa appendice contiene progetti completi end-to-end per consolidare le competenze Docker acquisite. Ogni progetto include Dockerfile ottimizzato, docker-compose.yml, CI/CD pipeline, monitoring setup, e deployment strategy.

\begin{tcolorbox}[title=Progetti Inclusi]
\begin{enumerate}
\item \textbf{Full-Stack Web Application}: React + Node.js + PostgreSQL + Redis
\item \textbf{Microservices Architecture}: API Gateway + 3 Services + Message Queue
\item \textbf{WordPress Production Setup}: Nginx + PHP-FPM + MySQL + Redis
\item \textbf{Data Pipeline}: Apache Airflow + Postgres + Redis
\item \textbf{Monitoring Stack}: Prometheus + Grafana + Loki + Alertmanager
\item \textbf{CI/CD Platform}: Jenkins + Docker-in-Docker + Registry
\end{enumerate}
\end{tcolorbox}

\section{Progetto 1: Full-Stack MERN Application}

\subsection{Architettura}
\begin{verbatim}
┌─────────────┐
│   Nginx     │ :80 (Reverse Proxy + Static)
└──────┬──────┘
       │
   ┌───┴────┬─────────────┐
   │        │             │
┌──▼──┐  ┌──▼──────┐  ┌──▼────┐
│React│  │Node.js  │  │ Redis │
│ SPA │  │  API    │  │ Cache │
└─────┘  └────┬────┘  └───────┘
              │
         ┌────▼─────┐
         │PostgreSQL│
         │ Database │
         └──────────┘
\end{verbatim}

\subsection{Directory Structure}
\begin{lstlisting}[caption={Project Structure}]
fullstack-app/
├── frontend/
│   ├── Dockerfile
│   ├── package.json
│   ├── src/
│   └── public/
├── backend/
│   ├── Dockerfile
│   ├── package.json
│   ├── src/
│   └── tests/
├── nginx/
│   ├── Dockerfile
│   └── nginx.conf
├── docker-compose.yml
├── docker-compose.prod.yml
├── .env.example
├── .dockerignore
└── .github/
    └── workflows/
        └── ci-cd.yml
\end{lstlisting}

\subsection{Frontend Dockerfile}
\begin{lstlisting}[language=docker, caption={frontend/Dockerfile}]
# syntax=docker/dockerfile:1.4

# Stage 1: Build
FROM node:20-alpine AS builder

WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci

# Build application
COPY . .
RUN npm run build

# Stage 2: Production
FROM nginx:alpine

# Copy built assets
COPY --from=builder /app/build /usr/share/nginx/html

# Custom nginx config
COPY nginx.conf /etc/nginx/conf.d/default.conf

# Health check
HEALTHCHECK --interval=30s --timeout=3s \
    CMD wget --quiet --tries=1 --spider http://localhost/health || exit 1

EXPOSE 80
\end{lstlisting}

\subsection{Backend Dockerfile}
\begin{lstlisting}[language=docker, caption={backend/Dockerfile}]
# syntax=docker/dockerfile:1.4

FROM node:20-alpine AS base
RUN apk add --no-cache dumb-init
WORKDIR /app

# Dependencies
FROM base AS dependencies
COPY package*.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci --only=production

# Build
FROM base AS builder
COPY package*.json ./
RUN --mount=type=cache,target=/root/.npm \
    npm ci
COPY . .
RUN npm run build

# Test
FROM builder AS test
ENV NODE_ENV=test
RUN npm run test

# Production
FROM base AS production

# Security: non-root user
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

# Copy artifacts
COPY --from=dependencies --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --chown=nodejs:nodejs package.json ./

USER nodejs

HEALTHCHECK --interval=30s --timeout=3s --start-period=40s \
    CMD node healthcheck.js || exit 1

EXPOSE 3000

ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/server.js"]
\end{lstlisting}

\subsection{Docker Compose - Development}
\begin{lstlisting}[language=yaml, caption={docker-compose.yml}]
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${DB_NAME:-appdb}
      POSTGRES_USER: ${DB_USER:-appuser}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-changeme}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./backend/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-appuser}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend

  # Redis Cache
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - backend

  # Backend API
  backend:
    build:
      context: ./backend
      target: development
    environment:
      NODE_ENV: development
      DATABASE_URL: postgresql://${DB_USER:-appuser}:${DB_PASSWORD:-changeme}@postgres:5432/${DB_NAME:-appdb}
      REDIS_URL: redis://redis:6379
      JWT_SECRET: ${JWT_SECRET:-dev-secret}
    volumes:
      - ./backend/src:/app/src
      - ./backend/package.json:/app/package.json
      - backend-modules:/app/node_modules
    ports:
      - "3000:3000"
      - "9229:9229"  # Debugger
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - backend
      - frontend
    command: npm run dev

  # Frontend React App
  frontend:
    build:
      context: ./frontend
      target: development
    environment:
      REACT_APP_API_URL: http://localhost:3000
      CHOKIDAR_USEPOLLING: "true"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
      - ./frontend/package.json:/app/package.json
      - frontend-modules:/app/node_modules
    ports:
      - "8080:3000"
    networks:
      - frontend
    command: npm start

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
    depends_on:
      - backend
      - frontend
    networks:
      - frontend

  # Adminer (Database GUI)
  adminer:
    image: adminer:latest
    ports:
      - "8081:8080"
    networks:
      - backend
    environment:
      ADMINER_DEFAULT_SERVER: postgres

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
  backend-modules:
  frontend-modules:
\end{lstlisting}

\subsection{Docker Compose - Production}
\begin{lstlisting}[language=yaml, caption={docker-compose.prod.yml}]
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - backend
    secrets:
      - db_password
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    networks:
      - backend
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  backend:
    image: myregistry.io/backend:${VERSION:-latest}
    environment:
      NODE_ENV: production
      DATABASE_URL_FILE: /run/secrets/database_url
      REDIS_URL_FILE: /run/secrets/redis_url
      JWT_SECRET_FILE: /run/secrets/jwt_secret
    networks:
      - backend
      - frontend
    secrets:
      - database_url
      - redis_url
      - jwt_secret
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s

  frontend:
    image: myregistry.io/frontend:${VERSION:-latest}
    networks:
      - frontend
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  nginx:
    image: myregistry.io/nginx:${VERSION:-latest}
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - frontend
    depends_on:
      - backend
      - frontend
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

secrets:
  db_password:
    external: true
  database_url:
    external: true
  redis_url:
    external: true
  jwt_secret:
    external: true

networks:
  frontend:
    driver: overlay
  backend:
    driver: overlay
    internal: true

volumes:
  postgres-data:
  redis-data:
\end{lstlisting}

\subsection{Nginx Configuration}
\begin{lstlisting}[caption={nginx/nginx.conf}]
upstream backend {
    least_conn;
    server backend:3000 max_fails=3 fail_timeout=30s;
}

upstream frontend {
    server frontend:80;
}

# Rate limiting
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
limit_conn_zone $binary_remote_addr zone=addr:10m;

server {
    listen 80;
    server_name example.com;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=31536000" always;

    # Gzip compression
    gzip on;
    gzip_types text/plain text/css application/json application/javascript;
    gzip_min_length 1000;

    # API endpoints
    location /api {
        limit_req zone=api_limit burst=20 nodelay;
        limit_conn addr 10;

        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;

        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # Frontend SPA
    location / {
        proxy_pass http://frontend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        # SPA routing
        try_files $uri $uri/ /index.html;
    }

    # Static assets caching
    location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "OK\n";
        add_header Content-Type text/plain;
    }
}
\end{lstlisting}

\subsection{GitHub Actions CI/CD}
\begin{lstlisting}[language=yaml, caption={.github/workflows/ci-cd.yml}]
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository }}

jobs:
  test-backend:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: backend/package-lock.json

      - name: Install dependencies
        working-directory: backend
        run: npm ci

      - name: Run linter
        working-directory: backend
        run: npm run lint

      - name: Run tests
        working-directory: backend
        run: npm test
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/testdb

      - name: Build
        working-directory: backend
        run: npm run build

  test-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Run linter
        working-directory: frontend
        run: npm run lint

      - name: Run tests
        working-directory: frontend
        run: npm test -- --coverage

      - name: Build
        working-directory: frontend
        run: npm run build

  build-and-push:
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    permissions:
      contents: read
      packages: write

    strategy:
      matrix:
        service: [backend, frontend, nginx]

    steps:
      - uses: actions/checkout@v4

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=sha
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.service }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.service }}:buildcache
          cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}/${{ matrix.service }}:buildcache,mode=max

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
      - uses: actions/checkout@v4

      - name: Deploy to production
        run: |
          echo "Deploying to production..."
          # Add deployment commands here
\end{lstlisting}

\section{Progetto 2: Microservices Architecture}

\subsection{Architettura Microservices}
\begin{verbatim}
                    ┌─────────────┐
                    │   Traefik   │ API Gateway
                    │   :80/:443  │
                    └──────┬──────┘
                           │
         ┌─────────────────┼─────────────────┐
         │                 │                 │
    ┌────▼────┐      ┌────▼────┐      ┌────▼────┐
    │ User    │      │ Product │      │ Order   │
    │ Service │      │ Service │      │ Service │
    └────┬────┘      └────┬────┘      └────┬────┘
         │                │                 │
    ┌────▼────┐      ┌────▼────┐      ┌────▼────┐
    │MongoDB  │      │Postgres │      │Postgres │
    └─────────┘      └─────────┘      └─────────┘
         │                │                 │
         └────────────────┼─────────────────┘
                          │
                    ┌─────▼──────┐
                    │  RabbitMQ  │ Message Broker
                    └────────────┘
\end{verbatim}

\subsection{Microservices Docker Compose}
\begin{lstlisting}[language=yaml, caption={microservices/docker-compose.yml}]
version: '3.8'

services:
  # API Gateway - Traefik
  traefik:
    image: traefik:v2.10
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--metrics.prometheus=true"
    ports:
      - "80:80"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - microservices

  # User Service
  user-service:
    build:
      context: ./services/user
    environment:
      MONGO_URL: mongodb://mongodb:27017/users
      RABBITMQ_URL: amqp://rabbitmq:5672
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.user.rule=PathPrefix(`/api/users`)"
      - "traefik.http.services.user.loadbalancer.server.port=3000"
    depends_on:
      - mongodb
      - rabbitmq
    networks:
      - microservices
    deploy:
      replicas: 3

  # Product Service
  product-service:
    build:
      context: ./services/product
    environment:
      DATABASE_URL: postgresql://postgres:password@product-db:5432/products
      RABBITMQ_URL: amqp://rabbitmq:5672
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.product.rule=PathPrefix(`/api/products`)"
      - "traefik.http.services.product.loadbalancer.server.port=3000"
    depends_on:
      - product-db
      - rabbitmq
    networks:
      - microservices
    deploy:
      replicas: 3

  # Order Service
  order-service:
    build:
      context: ./services/order
    environment:
      DATABASE_URL: postgresql://postgres:password@order-db:5432/orders
      RABBITMQ_URL: amqp://rabbitmq:5672
      USER_SERVICE_URL: http://user-service:3000
      PRODUCT_SERVICE_URL: http://product-service:3000
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.order.rule=PathPrefix(`/api/orders`)"
      - "traefik.http.services.order.loadbalancer.server.port=3000"
    depends_on:
      - order-db
      - rabbitmq
    networks:
      - microservices
    deploy:
      replicas: 3

  # MongoDB for User Service
  mongodb:
    image: mongo:7
    volumes:
      - mongodb-data:/data/db
    networks:
      - microservices

  # PostgreSQL for Product Service
  product-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: products
      POSTGRES_PASSWORD: password
    volumes:
      - product-db-data:/var/lib/postgresql/data
    networks:
      - microservices

  # PostgreSQL for Order Service
  order-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: orders
      POSTGRES_PASSWORD: password
    volumes:
      - order-db-data:/var/lib/postgresql/data
    networks:
      - microservices

  # RabbitMQ Message Broker
  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - microservices

  # Prometheus
  prometheus:
    image: prom/prometheus:v2.48.0
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - microservices

  # Grafana
  grafana:
    image: grafana/grafana:10.2.0
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana-data:/var/lib/grafana
    networks:
      - microservices

networks:
  microservices:
    driver: overlay

volumes:
  mongodb-data:
  product-db-data:
  order-db-data:
  rabbitmq-data:
  prometheus-data:
  grafana-data:
\end{lstlisting}

\section{Progetto 3: WordPress Production}

\subsection{WordPress Stack}
\begin{lstlisting}[language=yaml, caption={wordpress/docker-compose.yml}]
version: '3.8'

services:
  nginx:
    image: nginx:alpine
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - wordpress-data:/var/www/html:ro
      - ./ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - wordpress
    networks:
      - frontend
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  wordpress:
    image: wordpress:php8.2-fpm-alpine
    environment:
      WORDPRESS_DB_HOST: mysql
      WORDPRESS_DB_USER: ${DB_USER}
      WORDPRESS_DB_PASSWORD_FILE: /run/secrets/db_password
      WORDPRESS_DB_NAME: ${DB_NAME}
      WORDPRESS_REDIS_HOST: redis
      WORDPRESS_REDIS_PORT: 6379
    volumes:
      - wordpress-data:/var/www/html
      - ./php.ini:/usr/local/etc/php/conf.d/custom.ini
    networks:
      - frontend
      - backend
    secrets:
      - db_password
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 512M

  mysql:
    image: mysql:8.0
    environment:
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${DB_USER}
      MYSQL_PASSWORD_FILE: /run/secrets/db_password
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/db_root_password
    volumes:
      - mysql-data:/var/lib/mysql
      - ./mysql-config:/etc/mysql/conf.d
    networks:
      - backend
    secrets:
      - db_password
      - db_root_password
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '2'
          memory: 2G

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - backend
    deploy:
      replicas: 1

  # WP-CLI for management
  wpcli:
    image: wordpress:cli
    user: "33:33"
    volumes:
      - wordpress-data:/var/www/html
    networks:
      - backend
    command: wp --info
    profiles:
      - tools

secrets:
  db_password:
    external: true
  db_root_password:
    external: true

networks:
  frontend:
    driver: overlay
  backend:
    driver: overlay
    internal: true

volumes:
  wordpress-data:
  mysql-data:
  redis-data:
\end{lstlisting}

\section{Progetto 4: Data Pipeline con Airflow}

\subsection{Apache Airflow Stack}
\begin{lstlisting}[language=yaml, caption={airflow/docker-compose.yml}]
version: '3.8'

x-airflow-common: &airflow-common
  image: apache/airflow:2.7.0
  environment:
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  redis:
    image: redis:latest
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    healthcheck:
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    deploy:
      replicas: 3

  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        exec /entrypoint airflow version

  flower:
    <<: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

volumes:
  postgres-db-volume:
\end{lstlisting}

\section{Esercizi Pratici}

\subsection{Esercizio 1: Multi-Stage Build Optimization}
\textbf{Obiettivo}: Ottimizzare un Dockerfile esistente riducendo image size del 70\%.

\textbf{Tasks}:
\begin{enumerate}
\item Convertire single-stage a multi-stage build
\item Implementare BuildKit cache mounts
\item Configurare .dockerignore completo
\item Misurare reduction in image size e build time
\end{enumerate}

\subsection{Esercizio 2: Zero-Downtime Deployment}
\textbf{Obiettivo}: Implementare blue-green deployment con Docker Swarm.

\textbf{Tasks}:
\begin{enumerate}
\item Setup Docker Swarm cluster (1 manager, 2 workers)
\item Deploy applicazione in ambiente "blue"
\item Deploy nuova versione in ambiente "green"
\item Implementare traffic switch script
\item Test rollback procedure
\end{enumerate}

\subsection{Esercizio 3: Complete Observability}
\textbf{Obiettivo}: Setup monitoring completo per microservices.

\textbf{Tasks}:
\begin{enumerate}
\item Deploy Prometheus + Grafana + Loki stack
\item Instrumentare 3 microservices con metrics
\item Configurare centralized logging
\item Creare Grafana dashboards
\item Setup alert rules e notification channels
\end{enumerate}

\subsection{Esercizio 4: Security Hardening}
\textbf{Obiettivo}: Applicare security best practices.

\textbf{Tasks}:
\begin{enumerate}
\item Scan existing images con Trivy/Snyk
\item Fix tutte le vulnerabilities CRITICAL/HIGH
\item Implementare non-root users
\item Configurare read-only filesystem
\item Setup secrets management con Vault
\item Implement image signing con Cosign
\end{enumerate}

\section{Progetti Challenge}

\subsection{Challenge 1: Production-Ready E-Commerce}
Build complete e-commerce platform con:
\begin{itemize}
\item Frontend: Next.js
\item Backend: NestJS API
\item Databases: PostgreSQL + MongoDB + Redis
\item Payment: Stripe integration
\item Email: SMTP service
\item Storage: MinIO (S3-compatible)
\item Search: Elasticsearch
\item CI/CD: GitHub Actions
\item Monitoring: Prometheus/Grafana
\item Requirements: 99.9\% uptime, <200ms API latency
\end{itemize}

\subsection{Challenge 2: Scalable Chat Application}
Real-time chat con WebSocket:
\begin{itemize}
\item Backend: Socket.io cluster
\item Message broker: Redis Pub/Sub
\item Database: PostgreSQL
\item Load balancer: HAProxy
\item Horizontal scaling: 3-10 instances
\item Features: Typing indicators, read receipts, file sharing
\item Metrics: Messages/sec, active connections, latency
\end{itemize}

\section{Soluzioni e Best Practices}

\subsection{Deployment Strategy Decision Matrix}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Strategy} & \textbf{Downtime} & \textbf{Resources} & \textbf{Complexity} \\
\hline
Recreate & High & Low & Low \\
Rolling & None & Medium & Medium \\
Blue-Green & None & High (2x) & Medium \\
Canary & None & Medium & High \\
A/B Testing & None & Medium & High \\
\hline
\end{tabular}

\subsection{Resource Sizing Guide}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Service Type} & \textbf{CPU} & \textbf{Memory} \\
\hline
Node.js API & 0.5-1 core & 256-512MB \\
React SPA (built) & 0.25 core & 128MB \\
PostgreSQL & 1-2 cores & 1-2GB \\
Redis & 0.5 core & 256-512MB \\
Nginx & 0.5 core & 128-256MB \\
\hline
\end{tabular}

\section{Riferimenti}

\begin{itemize}
\item Docker Samples: \url{https://github.com/docker/awesome-compose}
\item Production Patterns: \url{https://github.com/docker/docker-bench-security}
\item Kubernetes Patterns: \url{https://github.com/kubernetes/examples}
\item Microservices Examples: \url{https://microservices.io/patterns/}
\end{itemize}
